{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence Tagging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7nH8JuV4lDM",
        "colab_type": "text"
      },
      "source": [
        "## Sequence Tagging using Sequential Models\n",
        "\n",
        "Sequence Tagging is an information extraction technique to identify and classify named entities in text. These entities can be pre-defined and generic like location names, organizations, time and etc..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHeKLligaLLj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5949a8fa-7dd9-454b-dfb4-214c236114a4"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSImVOFbW2FE",
        "colab_type": "text"
      },
      "source": [
        "#### Desired Sample Output\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/2400/1*8LOMipM-fmszClg-AwATkQ.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoQJganAZHkl",
        "colab_type": "text"
      },
      "source": [
        "### Files required are given in below link\n",
        "\n",
        "https://drive.google.com/drive/folders/1m9JjfsAEN50flYwFPCgZWQ5nHXGt0ZwI?usp=sharing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjeai6wNhInF",
        "colab_type": "code",
        "outputId": "4825f446-e147-4d05-a187-55d4d0d0b442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "project_path = \"/content/drive/My Drive/AIML Notes/SequenceTagging/\"\n",
        "data_filename = \"ner_dataset.csv.zip\"\n",
        "\n",
        "import zipfile\n",
        "z = zipfile.ZipFile(project_path + data_filename, 'r')\n",
        "z.extractall()\n",
        "z.close()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Db22AItMH8V",
        "colab_type": "code",
        "outputId": "40b288b5-1e5e-4f38-f3fd-4b1c3de7a007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGWklWeAsaCF",
        "colab_type": "code",
        "outputId": "f5a14917-0782-4242-b7bd-ccc45a9380a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pwd"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTINlpIu3u_H",
        "colab_type": "code",
        "outputId": "601e8fb3-602d-4f34-b43a-fab42c20c03c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        }
      },
      "source": [
        "data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin-1\")\n",
        "# data = data.drop(['POS'], axis =1)\n",
        "# data = data.fillna(method=\"ffill\")\n",
        "data.head(30)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>through</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>London</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NaN</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>protest</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NaN</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NaN</td>\n",
              "      <td>war</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NaN</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NaN</td>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demand</td>\n",
              "      <td>VB</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NaN</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NaN</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>NaN</td>\n",
              "      <td>British</td>\n",
              "      <td>JJ</td>\n",
              "      <td>B-gpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NaN</td>\n",
              "      <td>troops</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NaN</td>\n",
              "      <td>from</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>NaN</td>\n",
              "      <td>that</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>NaN</td>\n",
              "      <td>country</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>NaN</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Families</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>NaN</td>\n",
              "      <td>soldiers</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>NaN</td>\n",
              "      <td>killed</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>NaN</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>NaN</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Sentence #           Word  POS    Tag\n",
              "0   Sentence: 1      Thousands  NNS      O\n",
              "1           NaN             of   IN      O\n",
              "2           NaN  demonstrators  NNS      O\n",
              "3           NaN           have  VBP      O\n",
              "4           NaN        marched  VBN      O\n",
              "5           NaN        through   IN      O\n",
              "6           NaN         London  NNP  B-geo\n",
              "7           NaN             to   TO      O\n",
              "8           NaN        protest   VB      O\n",
              "9           NaN            the   DT      O\n",
              "10          NaN            war   NN      O\n",
              "11          NaN             in   IN      O\n",
              "12          NaN           Iraq  NNP  B-geo\n",
              "13          NaN            and   CC      O\n",
              "14          NaN         demand   VB      O\n",
              "15          NaN            the   DT      O\n",
              "16          NaN     withdrawal   NN      O\n",
              "17          NaN             of   IN      O\n",
              "18          NaN        British   JJ  B-gpe\n",
              "19          NaN         troops  NNS      O\n",
              "20          NaN           from   IN      O\n",
              "21          NaN           that   DT      O\n",
              "22          NaN        country   NN      O\n",
              "23          NaN              .    .      O\n",
              "24  Sentence: 2       Families  NNS      O\n",
              "25          NaN             of   IN      O\n",
              "26          NaN       soldiers  NNS      O\n",
              "27          NaN         killed  VBN      O\n",
              "28          NaN             in   IN      O\n",
              "29          NaN            the   DT      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM1TrCKE36c-",
        "colab_type": "text"
      },
      "source": [
        "### Fill the NaN with Sentence tag to easily identify the words of a single sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOanGnGe3vBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.fillna(method=\"ffill\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAZi5z_74F3K",
        "colab_type": "text"
      },
      "source": [
        "### Drop POS column from dataset as we are only interested in tags for sentence tagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rscvylp13vDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.drop(['POS'], axis =1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmOZxR0Q3vGW",
        "colab_type": "code",
        "outputId": "ba6361f0-6e34-4360-af0e-ffc844e8c5ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        }
      },
      "source": [
        "data.head(30)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>through</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>London</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>protest</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>war</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Iraq</td>\n",
              "      <td>B-geo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demand</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>withdrawal</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>British</td>\n",
              "      <td>B-gpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>troops</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>from</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>that</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>country</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>Families</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>soldiers</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>killed</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Sentence: 2</td>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Sentence #           Word    Tag\n",
              "0   Sentence: 1      Thousands      O\n",
              "1   Sentence: 1             of      O\n",
              "2   Sentence: 1  demonstrators      O\n",
              "3   Sentence: 1           have      O\n",
              "4   Sentence: 1        marched      O\n",
              "5   Sentence: 1        through      O\n",
              "6   Sentence: 1         London  B-geo\n",
              "7   Sentence: 1             to      O\n",
              "8   Sentence: 1        protest      O\n",
              "9   Sentence: 1            the      O\n",
              "10  Sentence: 1            war      O\n",
              "11  Sentence: 1             in      O\n",
              "12  Sentence: 1           Iraq  B-geo\n",
              "13  Sentence: 1            and      O\n",
              "14  Sentence: 1         demand      O\n",
              "15  Sentence: 1            the      O\n",
              "16  Sentence: 1     withdrawal      O\n",
              "17  Sentence: 1             of      O\n",
              "18  Sentence: 1        British  B-gpe\n",
              "19  Sentence: 1         troops      O\n",
              "20  Sentence: 1           from      O\n",
              "21  Sentence: 1           that      O\n",
              "22  Sentence: 1        country      O\n",
              "23  Sentence: 1              .      O\n",
              "24  Sentence: 2       Families      O\n",
              "25  Sentence: 2             of      O\n",
              "26  Sentence: 2       soldiers      O\n",
              "27  Sentence: 2         killed      O\n",
              "28  Sentence: 2             in      O\n",
              "29  Sentence: 2            the      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ0tJd8T4T3G",
        "colab_type": "text"
      },
      "source": [
        "Now we can see from the above result that the same sentence words have same sentence id."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P-EYuc03vKi",
        "colab_type": "code",
        "outputId": "b0e8ce72-c6eb-4a24-bc8b-2088e2c71390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tags = list(set(data[\"Tag\"].values))\n",
        "n_tags = len(tags)\n",
        "n_tags"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le11ixSL3vNH",
        "colab_type": "code",
        "outputId": "8ec4d9f9-edd2-4757-caae-7cfd57540bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(tags)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B-nat', 'I-geo', 'I-gpe', 'B-geo', 'B-gpe', 'B-art', 'I-art', 'I-org', 'I-tim', 'B-eve', 'B-per', 'B-org', 'I-nat', 'I-per', 'I-eve', 'O', 'B-tim']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l7PJrtR8DkI",
        "colab_type": "code",
        "outputId": "190577e5-73d3-4cf7-883a-e3bf34ac8bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "words = set(list(data['Word'].values))\n",
        "words.add('dummy')\n",
        "n_words = len(words)\n",
        "n_words"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbQrtBlW7Yj5",
        "colab_type": "text"
      },
      "source": [
        "### Groupby sentences and combining words and tags for each setence using groupby and apply on dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qaC7K-E0EHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combining_words_tags = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),s[\"Tag\"].values.tolist())]\n",
        "d = data.groupby(\"Sentence #\").apply(combining_words_tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md7b3iM96hf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [s for s in d]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhhzcJcq7VLu",
        "colab_type": "code",
        "outputId": "0d6d3b3a-c2c4-41d8-83ab-b1fb4ce3b787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Thousands', 'O'),\n",
              " ('of', 'O'),\n",
              " ('demonstrators', 'O'),\n",
              " ('have', 'O'),\n",
              " ('marched', 'O'),\n",
              " ('through', 'O'),\n",
              " ('London', 'B-geo'),\n",
              " ('to', 'O'),\n",
              " ('protest', 'O'),\n",
              " ('the', 'O'),\n",
              " ('war', 'O'),\n",
              " ('in', 'O'),\n",
              " ('Iraq', 'B-geo'),\n",
              " ('and', 'O'),\n",
              " ('demand', 'O'),\n",
              " ('the', 'O'),\n",
              " ('withdrawal', 'O'),\n",
              " ('of', 'O'),\n",
              " ('British', 'B-gpe'),\n",
              " ('troops', 'O'),\n",
              " ('from', 'O'),\n",
              " ('that', 'O'),\n",
              " ('country', 'O'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f7YSaKO7lD4",
        "colab_type": "code",
        "outputId": "4471bac2-4a1f-48f0-e2e7-b213dd0a146c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(sentences))\n",
        "sentences = sentences[:3200]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GtUxCQx7zrL",
        "colab_type": "text"
      },
      "source": [
        "### Map words and tags to integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPYT-FiW7r25",
        "colab_type": "code",
        "outputId": "fdfc48ea-424f-40ba-9dd6-1fcd32780335",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "words2index = {w:i for i,w in enumerate(words)}\n",
        "tags2index = {t:i for i,t in enumerate(tags)}\n",
        "print(words2index['India'])\n",
        "print(tags2index['B-geo'])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11063\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESh_HoYh8R81",
        "colab_type": "text"
      },
      "source": [
        "#### Make all sentences equal length by appending a `dummy` token at the end of the sentence if the sentence is short. And if the sentence is long consider only `max_length` number of words from that sentence. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiIxf2Ly8IKD",
        "colab_type": "code",
        "outputId": "f5aec18b-eb0e-4a2d-be36-4cd63f4baa84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "max_len = 30\n",
        "X = [[w[0]for w in s] for s in sentences]\n",
        "new_X = []\n",
        "for seq in X:\n",
        "    new_seq = []\n",
        "    for i in range(max_len):\n",
        "        try:\n",
        "            new_seq.append(seq[i])\n",
        "        except:\n",
        "            new_seq.append(\"dummy\")\n",
        "    new_X.append(new_seq)\n",
        "new_X[0]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thousands',\n",
              " 'of',\n",
              " 'demonstrators',\n",
              " 'have',\n",
              " 'marched',\n",
              " 'through',\n",
              " 'London',\n",
              " 'to',\n",
              " 'protest',\n",
              " 'the',\n",
              " 'war',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'and',\n",
              " 'demand',\n",
              " 'the',\n",
              " 'withdrawal',\n",
              " 'of',\n",
              " 'British',\n",
              " 'troops',\n",
              " 'from',\n",
              " 'that',\n",
              " 'country',\n",
              " '.',\n",
              " 'dummy',\n",
              " 'dummy',\n",
              " 'dummy',\n",
              " 'dummy',\n",
              " 'dummy',\n",
              " 'dummy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQHpyqsd8_rT",
        "colab_type": "text"
      },
      "source": [
        "#### Similarly pad labels with `O` tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iczVpVo48nPV",
        "colab_type": "code",
        "outputId": "6338a121-5c0d-409d-9747-23ac41b79c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "y = [[tags2index[w[1]] for w in s] for s in sentences]\n",
        "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tags2index[\"O\"])\n",
        "y[0]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([15, 15, 15, 15, 15, 15,  3, 15, 15, 15, 15, 15,  3, 15, 15, 15, 15,\n",
              "       15,  4, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkZf3HQ29HFi",
        "colab_type": "text"
      },
      "source": [
        "### Split the dataset into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tZuy8KJ8zpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(new_X, y, test_size=0.2, random_state=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuE7pkUsFMb5",
        "colab_type": "code",
        "outputId": "71a25ac0-f083-4690-98a6-a9c2bdb97c95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_tr)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2560"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K31WCmJDGvEz",
        "colab_type": "code",
        "outputId": "c160441a-0f66-49ba-c453-a7cd42555033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(X_tr).shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2560, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk86lCbYFMfI",
        "colab_type": "code",
        "outputId": "3d20a2bf-ec70-4a67-e4e1-08ed4ce27da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(y_tr).shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2560, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if8ZLt-VVm2I",
        "colab_type": "text"
      },
      "source": [
        "### Using ELMO(Deep contextualized word representations) embeddings (like word2vec) as pre-trained word embeddings\n",
        "\n",
        "Link to paper: https://arxiv.org/pdf/1802.05365.pdf\n",
        "\n",
        "Importing these embeddings from tensorflow hub as given in this link - https://tfhub.dev/google/elmo/1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV3uLPRd828x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "# import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras import backend as K\n",
        "sess = tf.Session()\n",
        "K.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnvsP8tiNHBW",
        "colab_type": "code",
        "outputId": "b515d431-29d4-4675-a8c7-baa35c1aa7ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__, hub.__version__"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.14.0', '0.6.0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMMf5lxN9NJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/1\", trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thoyb27v9PGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ElmoEmbedding(x):\n",
        "    return elmo_model(inputs={\n",
        "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
        "                            \"sequence_len\": tf.constant(batch_size*[max_len])\n",
        "                      },\n",
        "                      signature=\"tokens\",\n",
        "                      as_dict=True)[\"elmo\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPSH9Ejq9U_C",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTDVQDrd9SSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, Input\n",
        "from keras.layers.merge import add\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T98XvSn79V7M",
        "colab_type": "code",
        "outputId": "cd922f71-5d21-4f37-c9a5-3a54f53d2f72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input_text = Input(shape=(max_len,), dtype=tf.string)\n",
        "embedding = Lambda(ElmoEmbedding, output_shape=(max_len, 1024))(input_text)\n",
        "x = Bidirectional(LSTM(units=50, return_sequences=True, dropout=0.2))(embedding)\n",
        "# x = Bidirectional(LSTM(units=50, return_sequences=True))(x)\n",
        "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(x)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Ma9XhItnRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_sparse_categorical_accuracy(y_true, y_pred):\n",
        "    return K.cast(K.equal(K.max(y_true, axis=-1),\n",
        "                          K.cast(K.argmax(y_pred, axis=-1), K.floatx())),\n",
        "                  K.floatx())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl2VsvsO9b5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(input_text, out)\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[custom_sparse_categorical_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGNYssNZ9d1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_tr = (np.arange(y_tr.max()+1) == y_tr[...,None]).astype(int)\n",
        "y_tr = y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FO8JYMCxNWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_te = y_te.reshape(y_te.shape[0], y_te.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVD9Qq3DoV2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79f25358-0a45-45f3-b702-bc3e8a9ffdc7"
      },
      "source": [
        "y_tr.shape"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2560, 30, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4Q1F4db5Vl_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99753479-81ef-4454-92e0-3f031378adee"
      },
      "source": [
        "y_te.shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(640, 30, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vss0_D6rVZHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv2QW1YJ9fnC",
        "colab_type": "code",
        "outputId": "07a1ed56-676f-467d-bd0f-49617521347e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "history = model.fit(np.array(X_tr), y_tr, batch_size=batch_size, epochs=1, verbose=1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "2560/2560 [==============================] - 533s 208ms/step - loss: 0.4884 - custom_sparse_categorical_accuracy: 0.8859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaYgTKA2cdUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "b0bc1150-4478-4d8a-e881-18f194140792"
      },
      "source": [
        "!pip install seqeval"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (0.0.12)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.14.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJsCtYQbvDO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5a2f3f1-56f5-406f-d953-bf7e8045ed1c"
      },
      "source": [
        "np.array(X_te[:]).shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(640, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg69jziFMpjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx2tag = {i: w for w, i in tags2index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRDD4-LvXUic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "test_pred = model.predict(np.array(X_te[:32*10]), verbose=1)\n",
        "\n",
        "idx2tag = {i: w for w, i in tags2index.items()}\n",
        "\n",
        "def pred2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            p_i = np.argmax(p)\n",
        "            out_i.append(idx2tag[p_i].replace(\"dummy\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i889iMAUABbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test2label(pred):\n",
        "    out = []\n",
        "    for pred_i in pred:\n",
        "        out_i = []\n",
        "        for p in pred_i:\n",
        "            out_i.append(idx2tag[p[0]].replace(\"dummy\", \"O\"))\n",
        "        out.append(out_i)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b2Kuy7nAD6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_labels = pred2label(test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7P1awWg_u7o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "94fa6d6f-1852-4388-bbc8-f10b5da30912"
      },
      "source": [
        "test_labels = test2label(y_te[:32*10])\n",
        "print(classification_report(test_labels, pred_labels))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           precision    recall  f1-score   support\n",
            "\n",
            "      org       0.08      0.01      0.02       141\n",
            "      per       0.35      0.31      0.33        95\n",
            "      tim       0.62      0.46      0.53       138\n",
            "      gpe       0.69      0.56      0.62        97\n",
            "      geo       0.54      0.58      0.56       242\n",
            "      art       0.00      0.00      0.00         4\n",
            "      eve       0.00      0.00      0.00         2\n",
            "      nat       0.00      0.00      0.00         2\n",
            "\n",
            "micro avg       0.53      0.40      0.46       721\n",
            "macro avg       0.45      0.40      0.42       721\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAQI4Ur4EHu7",
        "colab_type": "text"
      },
      "source": [
        "The score can be increased by considering full train data and increasing the epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku5AtCowDtmv",
        "colab_type": "text"
      },
      "source": [
        "### To visualize tags on text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClpZ-jR-A5fp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "cc93f235-cc04-42cc-baed-d88dd2c0f4d3"
      },
      "source": [
        "!pip install ipymarkup"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipymarkup\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/29/eaa1bcf649d6333dea829c05577c67f881d0555b6d77c1da72afda5c847d/ipymarkup-0.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: intervaltree==2.1.0 in /usr/local/lib/python3.6/dist-packages (from ipymarkup) (2.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.6/dist-packages (from intervaltree==2.1.0->ipymarkup) (2.1.0)\n",
            "Installing collected packages: ipymarkup\n",
            "Successfully installed ipymarkup-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6_KQvPJK69R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ipymarkup import show_box_markup\n",
        "from ipymarkup.palette import palette, BLUE, RED, GREEN, ORANGE, PURPLE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiP4BTiUKy2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = X_te[2]\n",
        "text = ' '.join(test)\n",
        "\n",
        "spans = []\n",
        "current_pos2 = 0\n",
        "for index, i in enumerate(test):\n",
        "  if index<max_len and i !=\"dummy\":\n",
        "    if len(idx2tag[y_te[2][index][0]].split('-'))>1:\n",
        "      tag = idx2tag[y_te[2][index][0]].split('-')[1]\n",
        "    else:\n",
        "      tag = idx2tag[y_te[2][index][0]].split('-')[0]\n",
        "    \n",
        "    current_pos1 = current_pos2\n",
        "    current_pos2 += len(i)+1\n",
        "    if current_pos2 > current_pos1:\n",
        "      spans.append( (current_pos1, current_pos2, tag) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wouWxu-9K0S_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "ef4d4f14-58e7-4c1b-b465-ce625e32a4ad"
      },
      "source": [
        "spans"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 10, 'O'),\n",
              " (10, 14, 'O'),\n",
              " (14, 18, 'O'),\n",
              " (18, 23, 'O'),\n",
              " (23, 27, 'O'),\n",
              " (27, 36, 'O'),\n",
              " (36, 39, 'O'),\n",
              " (39, 43, 'O'),\n",
              " (43, 50, 'O'),\n",
              " (50, 54, 'O'),\n",
              " (54, 63, 'O'),\n",
              " (63, 73, 'tim'),\n",
              " (73, 76, 'O'),\n",
              " (76, 80, 'O'),\n",
              " (80, 88, 'O'),\n",
              " (88, 97, 'O'),\n",
              " (97, 105, 'O'),\n",
              " (105, 109, 'O'),\n",
              " (109, 116, 'geo'),\n",
              " (116, 123, 'O'),\n",
              " (123, 128, 'O'),\n",
              " (128, 135, 'O'),\n",
              " (135, 139, 'O'),\n",
              " (139, 146, 'gpe'),\n",
              " (146, 153, 'O'),\n",
              " (153, 155, 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOcUqZfQK1BS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "456e4117-798f-4c75-f38d-77e7d0a5a495"
      },
      "source": [
        "show_box_markup(text, spans, palette=palette(tim=BLUE, geo=RED, gpe=ORANGE, O=PURPLE))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">Officials <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">say <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">the <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">bomb <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">was <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">attached <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">to <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">the <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">tanker <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">and <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">exploded <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Wednesday <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">tim</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">as <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">the <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">vehicle <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">traveled <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">through <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">the <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffcdd2; background: #ffebee\">Khyber <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #e57373;\">geo</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">tribal <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">area <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">toward <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">the <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #ffe0b2; background: #fff3e0\">Afghan <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #ffb74d;\">gpe</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">border <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #d1c4e9; background: #ede7f6\">. <span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #9575cd;\">O</span></span>dummy dummy dummy dummy</div>"
            ],
            "text/plain": [
              "BoxMarkup('Officials say the bomb was attached to the tanker and exploded Wednesday as the vehicle traveled through the Khyber tribal area toward the Afghan border . dummy dummy dummy dummy',\n",
              "          [Span(0, 10, 'O'),\n",
              "           Span(10, 14, 'O'),\n",
              "           Span(14, 18, 'O'),\n",
              "           Span(18, 23, 'O'),\n",
              "           Span(23, 27, 'O'),\n",
              "           Span(27, 36, 'O'),\n",
              "           Span(36, 39, 'O'),\n",
              "           Span(39, 43, 'O'),\n",
              "           Span(43, 50, 'O'),\n",
              "           Span(50, 54, 'O'),\n",
              "           Span(54, 63, 'O'),\n",
              "           Span(63, 73, 'tim'),\n",
              "           Span(73, 76, 'O'),\n",
              "           Span(76, 80, 'O'),\n",
              "           Span(80, 88, 'O'),\n",
              "           Span(88, 97, 'O'),\n",
              "           Span(97, 105, 'O'),\n",
              "           Span(105, 109, 'O'),\n",
              "           Span(109, 116, 'geo'),\n",
              "           Span(116, 123, 'O'),\n",
              "           Span(123, 128, 'O'),\n",
              "           Span(128, 135, 'O'),\n",
              "           Span(135, 139, 'O'),\n",
              "           Span(139, 146, 'gpe'),\n",
              "           Span(146, 153, 'O'),\n",
              "           Span(153, 155, 'O')])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}